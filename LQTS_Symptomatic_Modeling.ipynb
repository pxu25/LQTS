{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model to predict symptomatic status of LQTS using clinical, genetic and demographic features                \n",
    "#### *Written by Peng Xu (xu.peng@mayo.edu)*    \n",
    "\n",
    "#### Dataset\n",
    "##### The whole cohort has LQTS patients and non-LQTS patients including QTc, Age, Gender and LQTs, family history features, etc.\n",
    "\n",
    "#### Aim:\n",
    "##### To predict the symptomatic status of LQTS using all of possible avaible features so the new model can outperform the Prior model....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nessacery modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# # Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classification metrics (added later)\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the whole cohort dataset and select LQTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(file_name):\n",
    "    \"\"\"Load the dataset and print the row# and column#.\"\"\"\n",
    "    df = pd.read_csv(file_name)\n",
    "    display(df.head(3))\n",
    "    print(f\"{df.shape[0]} samples and {df.shape[1]} columns.\")\n",
    "    return df\n",
    "\n",
    "def columns_list(df):\n",
    "    print(\"Index: Column Name\")\n",
    "    for i in range(0,len(df.columns)):\n",
    "        print(str(i),\":\", df.columns[i])\n",
    "\n",
    "fileName = 'LQTS_Proband_09062019.csv'\n",
    "df_raw = data_loader(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "plt.style.use('_classic_test')\n",
    "\n",
    "def distplot(obs1, obs2, bins, x1, x2, figName, style):\n",
    "    \"\"\"Plot the observation distribution\"\"\"\n",
    "    \n",
    "    sns.set(style='white')\n",
    "    \n",
    "    if style == 'hist':\n",
    "        plt.ylabel('The number of patients')\n",
    "        sns.distplot(obs1,bins=bins, color='red', kde=False)\n",
    "        if obs2 is not None:\n",
    "            sns.distplot(obs2, bins =bins, color='black', kde=False)\n",
    "        plt.ylabel('The number of patients')\n",
    "    \n",
    "    elif style =='curve':\n",
    "        sns.distplot(obs1,bins=bins, color='red', hist=False, kde_kws={\"shade\": True})\n",
    "        if obs2 is not None:\n",
    "            sns.distplot(obs2, bins =bins, color='black', hist=False, kde_kws={\"shade\": True})\n",
    "    elif style =='hist+curve':\n",
    "        sns.distplot(obs1,bins=bins, color='red')\n",
    "        if obs2 is not None:\n",
    "            sns.distplot(obs2, bins =bins, color='black')\n",
    "        \n",
    "    plt.xlim(x1, x2)\n",
    "    plt.savefig(figName, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def cat_feature(df,feature_col, label_col, label_value):\n",
    "    \"\"\"Statistic of feature agaist label\"\"\"\n",
    "    i = label_value\n",
    "    for f in df[feature_col].unique():\n",
    "        penc = df[(df[feature_col] == \n",
    "                   f) & (df[label_col] == i)].shape[0] / df[df[feature_col] == f].shape[0]\n",
    "        print(f'{f} in {feature_col}:  {100*round(penc,2)}%')\n",
    "        \n",
    "df_LQTS = df_raw\n",
    "df_symp = df_LQTS[df_LQTS['SymptomLifeTime'] == 1]\n",
    "df_LQTS.describe()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature1 : Proband\n",
    "###### 70.1% Proband family has the symptoms while only 16.5% related family members are symptomatic\n",
    "#### Feature 2: Age at Event\n",
    "##### Age at the first cardio event will be split before 30 and after 30 because more symptomatic patients are present before 30.\n",
    "#### Feature 3: Gender at Event\n",
    "##### 40.2% female has the symptoms while only 27.4% male are symptomatic.\n",
    "#### Feature 4: Genetic variant\n",
    "##### LQT1,2,3 and Multiple Mutation\n",
    "#### Feature 5: Family history of sudden cardiac death \n",
    "#### Is there a family history of sudden cardiac death under the age of 45?  If Yes, there is a family history. For sympmatic LQTS patients, \n",
    "##### No :  40.17% ; Yes :  29.87% ;Unknown:  50.0%\n",
    "#### Feature 6: History of LQTS?\n",
    "##### Is there a family history of LQTS?  If there is a LQTS listed, then they have a family history. For sympmatic LQTS patients, \n",
    "##### Yes :  29%\n",
    "#### Feature 7: QTc\n",
    "##### QTc comes from computed QTc value at baseline for the patient (typically the first visit with Dr. Ackerman) with Dr. Ackerman correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Features  ################################\n",
    "#############Demographic\n",
    "## Age\n",
    "obs1 = df_LQTS[df_LQTS['SymptomLifeTime'] == 1]['age_first_cardia_event']\n",
    "obs2 = df_LQTS[df_LQTS['SymptomLifeTime'] == 0]['age_first_cardia_event']\n",
    "x1 = 0\n",
    "x2 = 80\n",
    "style = 'hist+curve'\n",
    "bins = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 65, 75]\n",
    "figName = 'Age at LQTS whole cohort.png'\n",
    "distplot(obs1, obs2, bins, x1, x2, figName, style)\n",
    "##Gender\n",
    "df_LQTS.groupby(['Gender','SymptomLifeTime'])['MRN#'].count()\n",
    "print(f'{round(100*305/(305+453),1)}% female has the symptoms.')\n",
    "print(f'{round(100*151/(151+400),1)}% male has the symptoms.')\n",
    "\n",
    "#############Genetic\n",
    "print('Symptom in Life(yes:1, no:0)')\n",
    "print('---------------------------')\n",
    "for col in ['LQTS 1 (KCNQ1)','LQTS 2 (KCNH2)','LQTS 3 (SCN5A)','LQTS Multiple Mutations','LQTS Minor Genes']:\n",
    "    cat_feature(df_LQTS,col,'SymptomLifeTime',1)\n",
    "    print() \n",
    "\n",
    "#f, ax = plt.subplots(figsize=(10, 10))\n",
    "data = round(df_LQTS['LQTS 1 (KCNQ1)','LQTS 2 (KCNH2)','LQTS 3 (SCN5A)','LQTS Multiple Mutations','LQTS Minor Genes'].corr(), 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.heatmap(data=round(data, annot = True, square = True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#############Clinical\n",
    "##Proband\n",
    "print('Category                % with symptoms')\n",
    "df_LQTS.groupby(['Proband','SymptomLifeTime'])['MRN#'].count()\n",
    "print(f'{round(100*314/(313+135),1)}% Proband family has the symptoms')\n",
    "print(f'{round(100*142/(142+718),1)}% Related family member has the symptoms')\n",
    "##Family history of sudden cardiac death\n",
    "cat_feature(df_LQTS,'History of SCD','SymptomLifeTime', 1)\n",
    "##Family of LQTC\n",
    "cat_feature(df_LQTS,'History of LQTS','SymptomLifeTime', 1)\n",
    "## QTc\n",
    "obs1 = df_LQTS[df_LQTS['SymptomLifeTime'] == 1]['QTc']\n",
    "obs2 = df_LQTS[df_LQTS['SymptomLifeTime'] == 0]['QTc']\n",
    "x1 = 350\n",
    "x2 = 751\n",
    "style = 'hist+curve'\n",
    "bins_QTc = [370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610,630,751]\n",
    "figName = 'QTc_all_features.png'\n",
    "distplot(obs1, obs2, bins_QTc, x1, x2, figName, style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature engineering \n",
    "\n",
    "#### Based on the feature selection results, we will use \n",
    "1. clinical variables: QTc, Gender, Age, Family history of Sudden Cardio Death, LQTS family\n",
    "1. genetic variables:  LQTS 1 (KCNQ1),LQTS 2 (KCNH2),LQTS 3 (SCN5A),LQTS Multiple Mutation,LQTS Minor Genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PreProcessing ################################\n",
    "#######1. Transform Proband, Gender as dummy variable            ########\n",
    "#######2. Transform History of SCD as dummy variable             ########\n",
    "#######3. Transform History of LQTS as dummy variable            ########\n",
    "#######4. Transform Age(<=30 or >30) as dummy variable           ########\n",
    "#######5. Add QTc as dummary variable (>=500 or <500ms)          ########\n",
    "#######6. Standerscale the QTc                                   ########\n",
    "\n",
    "clinical_cols = ['Proband','QTc','Gender','age_first_cardia_event',\n",
    "                 'History of SCD','History of LQTS']\n",
    "genetic_cols = ['LQTS 1 (KCNQ1)','LQTS 2 (KCNH2)','LQTS 3 (SCN5A)',\n",
    "                'LQTS Multiple Mutations','LQTS Minor Genes']\n",
    "target_var = ['SymptomLifeTime']\n",
    "feature_cols = clinical_cols+genetic_cols+target_var\n",
    "df_features = df_LQTS[feature_cols]\n",
    "\n",
    "def LQTS_PreProcessing(df):\n",
    "    \"\"\"PreProcessing the features for LQTS\"\"\"\n",
    "    replace_val = {'Proband':{'Proband':1, 'Related family member':0},\n",
    "                   'Gender': {'Female': 1, 'Male':0},\n",
    "                   'History of SCD':{'Yes':1, 'No':0, 'Unknown':0}, \n",
    "                   'History of LQTS':{'LQTS':1, 'None':0, 'Unknown':0, '0':0,\n",
    "                                      'ARVC':0,'Other':0}}\n",
    "    df_prep = df.replace(replace_val)\n",
    "    df_prep['Age(<=30)']=[1 if age <=30 else 0 for age in df['age_first_cardia_event']]\n",
    "    df_prep['QTc(>=500)']=[1 if QTc >=500 else 0 for QTc in df['QTc']]\n",
    "    #QTc standard scaler\n",
    "    QTc_mean = df['QTc'].mean()\n",
    "    QTc_std = df['QTc'].std()\n",
    "    df_prep['QTc_standard']=[(age-QTc_mean)/QTc_std for age in df['QTc']]\n",
    "    \n",
    "    return df_prep\n",
    "\n",
    "df_preprocess = LQTS_PreProcessing(df_features)\n",
    "\n",
    "#### Save the file as feature variables\n",
    "feature_cols = ['Proband','QTc_standard','QTc(>=500)','Gender','Age(<=30)',\n",
    "                'History of SCD','History of LQTS',\n",
    "                'LQTS 1 (KCNQ1)','LQTS 2 (KCNH2)','LQTS 3 (SCN5A)',\n",
    "                'LQTS Multiple Mutations', 'LQTS Minor Genes']\n",
    "target_var = ['SymptomLifeTime']\n",
    "\n",
    "df_model = df_preprocess[feature_cols + target_var]\n",
    "df_model.to_csv('LQTS_model_whole_cohort_proband.csv') # save the file for further maching learning\n",
    "\n",
    "## Read the Proprecessing\n",
    "#df_model = pd.read_csv('LQTS_model_whole_cohort_proband.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Modeling dataset #############################\n",
    "#######1. Proband                                                ########\n",
    "#######2. No Proband                                             ########\n",
    "#######3. Priori                                                 ########\n",
    "\n",
    "df_ml_no_proband = df_model[['QTc_standard', 'Gender', 'Age(<=30)', \n",
    "                             'History of SCD','History of LQTS', \n",
    "                             'LQTS 1 (KCNQ1)', 'LQTS 2 (KCNH2)', 'LQTS 3 (SCN5A)',\n",
    "                             'LQTS Multiple Mutations', 'LQTS Minor Genes', \n",
    "                             'SymptomLifeTime']]\n",
    "\n",
    "df_ml_proband = df_model[['Proband','QTc_standard', 'Gender', 'Age(<=30)', \n",
    "                          'History of SCD','History of LQTS', \n",
    "                          'LQTS 1 (KCNQ1)', 'LQTS 2 (KCNH2)', 'LQTS 3 (SCN5A)',\n",
    "                          'LQTS Multiple Mutations', 'LQTS Minor Genes', \n",
    "                          'SymptomLifeTime']]\n",
    "\n",
    "df_ml_Priori = df_model[['LQTS 1 (KCNQ1)', \n",
    "                         'LQTS 2 (KCNH2)',\n",
    "                         'LQTS 3 (SCN5A)',\n",
    "                         'QTc(>=500)', \n",
    "                         'Gender','SymptomLifeTime',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine learning\n",
    "\n",
    "#### Run the machine learning pipeline and find the winner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRocData(hot_y,y_score,wantedClass=0):\n",
    "    \"\"\"Use the The Closest to (0,1) as threshold\"\"\"\n",
    "    i =wantedClass\n",
    "    if ((hot_y.shape[1:]==()) & (y_score.shape[1:]==()) ): # Vector ROC\n",
    "        hot_y_use = hot_y \n",
    "        y_score_use = y_score \n",
    "    else:\n",
    "        hot_y_use = hot_y[:, i]\n",
    "        y_score_use = y_score[:, i]\n",
    "    \n",
    "    fpr , tpr , th  = roc_curve(hot_y_use, y_score_use)\n",
    "    roc_auc  = auc(fpr , tpr )\n",
    "    dist=np.sqrt((1-tpr )**2+(fpr)**2)\n",
    "    optimalIndex = np.argmin(dist)\n",
    "    return fpr , tpr,th, roc_auc, optimalIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Lasso Regression':LogisticRegression(penalty='l1',solver='liblinear',random_state=42),\n",
    "    'Gaussian NaiveBayes': GaussianNB(),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    #'SVM': SVC(probability=True, random_state=42,verbose=False),\n",
    "    'Linear SVM': SVC(kernel='linear',probability=True,random_state=42,verbose=False)\n",
    "    }\n",
    "#hyperparameters\n",
    "l1_hyperparameters = {'C': [1e-5,1e-4,1e-3,1e-2,1e-1,1,10,1e2,1e3,1e4,1e5]}\n",
    "ngb_hyperparameters = {}\n",
    "rf_hyperparameters = {'n_estimators': [50, 100, 200]}\n",
    "                      #'max_features': ['sqrt', 0.33]}\n",
    "svm_linear_hyperparameters = {'C': [0.01,0.1,0.5,1.0,5.0,10,20,40]}\n",
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {'Lasso Regression': l1_hyperparameters,\n",
    "                   'Gaussian NaiveBayes': ngb_hyperparameters,\n",
    "                   'RandomForest' : rf_hyperparameters, \n",
    "                   #'SVM': svm_hyperparameters,\n",
    "                   'Linear SVM':svm_linear_hyperparameters}\n",
    "\n",
    "def best_estimator(X, y, kfold, scoring, model, hyperparameter):\n",
    "    \"\"\"Classifier with Logistic Regression, Random Forest, SVM, Naive Bayes\n",
    "    \"\"\"\n",
    "    # Train the model and return the best estimator using GridSeearCV\n",
    "    clf = GridSearchCV(model,\n",
    "                       hyperparameter,\n",
    "                       scoring=scoring,\n",
    "                       cv=kfold,\n",
    "                       n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    return clf.best_estimator_\n",
    "\n",
    "def data_split(df, label, random_seed):\n",
    "    \"\"\"Split the data into training and testing set\"\"\"\n",
    "    # Split the data\n",
    "    y = df[label]\n",
    "    X = df.drop(label, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=random_seed,\n",
    "                                                        stratify=df[label])\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def model_performance_test(model, X_test, y_test):\n",
    "    \n",
    "    clf = model\n",
    "    #testing dataset to get the predict and proba\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    \n",
    "    #Optimal threthod\n",
    "    fpr, tpr, th, roc_auc, optimalIndex = getRocData(y_test.values,y_proba[:,1])\n",
    "    optimalTh = th[optimalIndex]\n",
    "    est_y_binary = y_proba[:,1]>=optimalTh\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test.values, est_y_binary).ravel()\n",
    "    \n",
    "    #print(optimalTh)\n",
    "    auc_score = round(roc_auc, 3)\n",
    "    accuracy = round((tn+tp)/(tp+tn+fp+fn),3)\n",
    "    sensitivity = round(tp/(tp+fn),3)\n",
    "    specificity = round(tn/(tn+fp),3)\n",
    "    \n",
    "    metric_score = [auc_score, accuracy, sensitivity, specificity]\n",
    "    #cm = confusion_matrix(y_test.values, est_y_binary)\n",
    "    return metric_score\n",
    "    \n",
    "    \n",
    "def machine_learning_pipeline(df,label, kfold, scoring):\n",
    "    # split the data\n",
    "    X_train, X_test, y_train, y_test = data_split(df, label)\n",
    "    \n",
    "    # find the best estimators and their performace metrics\n",
    "    model_metrics = {}\n",
    "    model_metrics['Metrics'] = ['ROC AUC Score','Accuracy','Sensitivity','Specificity']\n",
    "    for model_name in models.keys():\n",
    "        print(model_name)\n",
    "        clf = best_estimator(X_train, y_train, kfold, scoring, \n",
    "                             models[model_name], \n",
    "                             hyperparameters[model_name])\n",
    "        clf.fit(X_train, y_train)\n",
    "        metric_score, cm = model_performance_test(clf, X_test, y_test)\n",
    "        model_metrics[model_name] = metric_score\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(model_metrics)\n",
    "    df.set_index('Metrics', inplace=True)\n",
    "    \n",
    "    df_sorted_by_auc = df.sort_values(by='ROC AUC Score', axis=1, ascending=False)\n",
    "    display(df_sorted_by_auc)\n",
    "    \n",
    "def boostrap(df):\n",
    "    \"\"\"Returen the boostrapping model performance results\"\"\"\n",
    "    for name in ['Lasso Regression','Gaussian NaiveBayes','RandomForest','Linear SVM']:\n",
    "        auc_list = []\n",
    "        acc_list = []\n",
    "        sen_list = []\n",
    "        spe_list = []\n",
    "        for random_seed in range(0,1000):\n",
    "            X_train, X_test, y_train, y_test = data_split(df,'SymptomLifeTime', random_seed)\n",
    "            clf = best_estimator(X_train, y_train, 5, 'roc_auc', models[name], hyperparameters[name])\n",
    "            clf.fit(X_train, y_train)\n",
    "            metric_score = model_performance_test(clf, X_test, y_test)\n",
    "            auc_score, accuracy, sensitivity, specificity = metric_score\n",
    "            auc_list.append(auc_score)\n",
    "            acc_list.append(accuracy)\n",
    "            sen_list.append(sensitivity)\n",
    "            spe_list.append(specificity)\n",
    "        print(name)\n",
    "        print(f'AUC: {np.percentile(auc_list,50)},{np.percentile(auc_list,2.5)},{np.percentile(auc_list,97.5)}')\n",
    "        print(f'Accuracy: {np.percentile(acc_list,50)},{np.percentile(acc_list,2.5)},{np.percentile(acc_list,97.5)}')\n",
    "        print(f'Sensitivity: {np.percentile(sen_list,50)},{np.percentile(sen_list,2.5)},{np.percentile(sen_list,97.5)})')\n",
    "        print(f'Specificity: {np.percentile(spe_list,50)},{np.percentile(spe_list,2.5)},{np.percentile(spe_list,97.5)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the \n",
    "boostrap(df_proband)\n",
    "boostrap(df_no_Proband)\n",
    "boostrap(df_Priori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the model\n",
    "def roc_matrix(model_name, df, label):\n",
    "    X_train, X_test, y_train, y_test = data_split(df, label)\n",
    "    model = best_estimator(X_train, y_train, 5, 'roc_auc',models[model_name], hyperparameters[model_name])\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict_proba(X_test)\n",
    "    pred = [p[1] for p in pred]\n",
    "    fpr, trp, _ = roc_curve(y_test, pred)\n",
    "    auc_score   = auc(fpr, trp)\n",
    "    return fpr, trp, round(auc_score,3);\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('ROC(Receiver Operating Characteristic)')\n",
    "# Plot ROC curve\n",
    "\n",
    "\n",
    "metric = roc_matrix('Lasso Regression', df_ml_use, 'SymptomLifeTime')\n",
    "frp, trp, auc_score = metric[0], metric[1], metric[2]\n",
    "plt.plot(frp,trp,label=f'AUC = {auc_score}')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "# Diagonal 45 degree line\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "# Axes limits and labels\n",
    "# plt.xlim([0,1])\n",
    "# plt.ylim([0,1])\n",
    "plt.ylabel('Sensitivity',fontsize=12)\n",
    "plt.xlabel('1 - Specificity',fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig('ROC_all_features_Proband.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the model\n",
    "def roc_matrix(model_name, df, label):\n",
    "    X_train, X_test, y_train, y_test = data_split(df, label)\n",
    "    model = best_estimator(X_train, y_train, 5, 'roc_auc',models[model_name], hyperparameters[model_name])\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict_proba(X_test)\n",
    "    pred = [p[1] for p in pred]\n",
    "    fpr, trp, _ = roc_curve(y_test, pred)\n",
    "    auc_score   = auc(fpr, trp)\n",
    "    return fpr, trp, round(auc_score,3);\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('ROC(Receiver Operating Characteristic)')\n",
    "# Plot ROC curve\n",
    "metric = roc_matrix('Lasso Regression', df_ml_use, 'SymptomLifeTime')\n",
    "frp, trp, auc_score = metric[0], metric[1], metric[2]\n",
    "plt.plot(frp,trp,label=f\"Mayo's Features(AUC = {auc_score})\")\n",
    "\n",
    "metric = roc_matrix('Lasso Regression', df_ml_Priori, 'SymptomLifeTime')\n",
    "frp, trp, auc_score = metric[0], metric[1], metric[2]\n",
    "plt.plot(frp,trp,label=f\"Priori's Features(AUC = {auc_score})\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "# Diagonal 45 degree line\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "# Axes limits and labels\n",
    "# plt.xlim([0,1])\n",
    "# plt.ylim([0,1])\n",
    "plt.ylabel('Sensitivity',fontsize=12)\n",
    "plt.xlabel('1 - Specificity',fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig('ROC_Mayo_Priori.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Input Contribution\n",
    "#### Return the coefficients to determine the input contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input_contriubution(df):\n",
    "    \"\"\"Return the Logistic Regression coefficients\"\"\"\n",
    "    X_train, X_test, y_train, y_test = data_split(df, 'SymptomLifeTime')\n",
    "    model = best_estimator(X_train, y_train, 5, 'roc_auc',models['Lasso Regression'], hyperparameters['Lasso Regression'])\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Input name: {X_train.columns}\")\n",
    "    print(f\"Model Coefficience: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proband\n",
    "model_input_contriubution(df_model_proband)\n",
    "### no proband\n",
    "model_input_contriubution(df_model_no_proband)\n",
    "### \n",
    "model_input_contriubution(df_Priori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save winning model as final_model.pkl\n",
    "X_train, X_test, y_train, y_test = data_split(df_ml_proband, 'SymptomLifeTime')\n",
    "model = best_estimator(X_train, y_train, 5, 'roc_auc',models['Lasso Regression'], hyperparameters['Lasso Regression'])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "import pickle\n",
    "with open('LQTS_risk_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
